[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "教育測定学研究演習II",
    "section": "",
    "text": "はじめに\nこの資料は，東北大学大学院教育学研究科2025年度集中講義「教育測定学研究演習II」のためのものです。\nシラバスは以下の通りですが，集中講義という形式でもあり，受講者のみなさんの興味や関心などから柔軟に変更したいと考えています。\n\nオリエンテーション\nRと測定論の基礎1\nRと測定論の基礎2\n回帰分析1\n回帰分析2\n回帰分析の演習\n因子分析1\n因子分析2\n因子分析の演習\n測定の信頼性\nSEM1\nSEM2\nSEM3\nSEMの演習\nまとめ\n\n講義全体の目的は，構造方程式モデリング（Structural Equation Modeling; SEM）と呼ばれる汎用性の高い統計分析モデルを実践的に理解し， 自分の研究に役立てられるようになることです。\nRを使って実際に分析できるように，Rの基本的な考え方から 回帰分析，パス解析，因子分析を取り上げ，潜在変数を伴うパス解析とも呼ばれるSEMをRで実行できるよう実習します。\nRは非常に高機能な統計解析用の言語ですが， さらに機能を拡張し，SEMを自在に分析できるように lavaan（latent variable analysis）というパッケージを導入します。 その他にも分析に役立つパッケージを紹介する予定です。\n１日目は導入とRの基本的な操作， ２日目は回帰分析とパス解析モデル， ３日目で因子分析モデルと基本的なSEMを扱い， ４日目で少し拡張的なSEMまで進む予定です。\n訳の分からない暑さの中，せっかくの機会なので， みなさんのお役に立てるようがんばります。 ４日間よろしくお願いします。",
    "crumbs": [
      "はじめに"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  オリエンテーション",
    "section": "",
    "text": "みなさんの研究上の興味や関心を教えてください。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>オリエンテーション</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "path1.html",
    "href": "path1.html",
    "title": "5  パスモデル",
    "section": "",
    "text": "5.1 パス図\nパスモデル（path models），パス解析（path analysis）を通じて，パス図（path diagram）の考え方を習得し，回帰分析より柔軟なモデル構成に進みましょう。\n以下は，変数間の影響関係を記述するモデル式をグラフィカルに示す，パス図と呼ばれる描画手法 に用いられる記号，部品を示したものです。\nモデル式とパス図は一対一に対応します。AMOS（Analysis of MOment Structures; 積率構造分析）というソフトウェアが「お絵かきソフト」のように図を描くことでSEMが実行できるのも，このため（パス図を描けばモデル式が出力可能）です。なお，その特質が手法をおおいに普及させた，という側面もあります。\nよくみるパス図の慣行にしたがって，円と楕円を分けていますが，本質的には同じです。直接観測されない変数である誤差変数や潜在変数をマルで囲んで表します。多くの場合，「誤差」は円で，「能力」や「性格」など構成概念を表す潜在変数は楕円で表されますが，誤差を楕円で囲むこともありますし，円で囲まない記法もあります。\n三角形で定数（回帰分析における切片）を表します。ただし，基本的なSEMでは標準化されたデータを扱うため，パス図において主に使用されるパーツは，上図の三角形を除いた5つ（円／楕円を区別しなければ4つ）です。\n単方向の矢印で変数間を結び，両者の影響関係を表します。矢印を出す側が独立変数（説明変数）で，矢印を受ける側が従属変数（目的変数）です。その影響の程度，すなわち回帰分析における回帰係数を，パスモデルではパス係数（path coefficients）と呼び，矢印の上に表記します。\n双方向矢印は共変動の関係を表します。すなわち相関係数や共分散です。なお，単方向の矢印が２変数の間でお互いに向き合う（\\(X\\)が\\(Y\\)に影響し，\\(Y\\)が\\(X\\)に影響する）というモデルを構成することは（基本的には）できません。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>パスモデル</span>"
    ]
  },
  {
    "objectID": "path1.html#パスモデルとしての重回帰分析",
    "href": "path1.html#パスモデルとしての重回帰分析",
    "title": "5  パスモデル",
    "section": "5.2 パスモデルとしての重回帰分析",
    "text": "5.2 パスモデルとしての重回帰分析\n3つの独立変数から1つの従属変数を説明，予測する重回帰モデル \\[y = i + ax_1+bx_2+cx_3+誤差\\] を考えましょう。図の表記の便宜上，切片を \\(i\\) とし，\\(e\\) として表されることの多い誤差項を \\(誤差\\) と表すこととします。\n例えば，親の収入（\\(x_1\\)）と学業成績（\\(x_2\\)）と学業上の向上心（\\(x_3\\)）が，定量的に把握できる達成度（\\(y\\)）に与える影響の分析を想定します。\nパス図で表すと以下の通りです。\n\n定数である切片は，三角形で表される，常に値 \\(1\\) をとる変数からの係数 \\(i\\) として表されます。\n誤差変数においては，相関，共分散のような連動関係を表す双方向矢印が自分自身に刺さっています。自分自身との共分散なので，すなわち分散（標準化していれば標準偏差）を表します。ただ，この表記は省略される場合も多く，その場合は単に，分散を表すパラメータ（この場合は\\(g\\)）のみを表示します（その意味では，独立変数の分散を表す，自分自身にループする双方向矢印はほとんどの場合に省略されている，ともいえます［ループ双方向矢印を独立変数に示す場合もある］）。\nパス係数は必ずしも標準化解に統一する必要はありませんが，以降は，データを標準化し，以下の100人分のデータから計算された相関係数行列に基づいて考察することとします。\n\n重回帰モデルは切片を除いて \\[y = ax_1+bx_2+cx_3+誤差\\] と表され，三角形と矢印と \\(i\\) を除いたものが該当のパス図になります。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>パスモデル</span>"
    ]
  },
  {
    "objectID": "path1.html#相関係数のパラメータ表示",
    "href": "path1.html#相関係数のパラメータ表示",
    "title": "5  パスモデル",
    "section": "5.3 相関係数のパラメータ表示",
    "text": "5.3 相関係数のパラメータ表示\nここで，4変数間の相関係数と，（定数項を除いた）パス図の対応を考えましょう。\n相関係数行列は，４つの変数の連動関係を示しています。そこに方向はありません。\n一方で，取り上げているパスモデル（重回帰モデル）においては，\\(a\\)，\\(b\\)，\\(c\\) のパス係数（標準化偏回帰係数）と独立変数間の相関係数 \\(d\\)，\\(e\\)，\\(f\\)，誤差の分散（標準偏差） \\(g\\) といったモデルを特徴づけるパラメータが導入され，変数 \\(y\\)（達成度）は他の3つの影響を受けて値が変化する，という考え（仮説，モデル） が示されています。\nこれはつまり \\[\nx_1 と y \\ の相関 = a + (d \\times b) + (e\\times c)\n\\] のように再表現したということです。\\(x_1\\) と \\(y\\) はどのように連結（相関）しているのか，トレーシングルール（tracing rules）と呼ばれる考え方で，適切な \\(x_1\\) と \\(y\\) の経路（パス）を特定し，上式の関係を導くことができます。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>パスモデル</span>"
    ]
  },
  {
    "objectID": "path1.html#トレーシングルール",
    "href": "path1.html#トレーシングルール",
    "title": "5  パスモデル",
    "section": "5.4 トレーシングルール",
    "text": "5.4 トレーシングルール\nパス図において，２つの変数または１つの変数に注目し，その変数に至るパスを辿って，各パスの係数を掛け，可能なパスすべての結果を足し合わせます。ただし，\n\n単方向矢印を逆向きに辿り始めることは可能ですが，順行したらもう逆行はできません。\n一回通った変数を，もう一度通過することはできません。\n経路には，双方向矢印を最大でも１つしか含められません。\n\n\\(x_1\\) と \\(y\\) に注目しましょう。まず，ダイレクトなパスがあります。パス係数は \\(a\\)（のみ）です。次に，双方向矢印（相関 \\(d\\)）を辿って\\(x_2\\)に行き，\\(x_2\\) から \\(y\\) に至るパスがあります（係数 \\(b\\) ）。したがって，\\((d \\times b)\\) です。最後に，\\((e \\times c)\\)となります。\\(x_1\\) から \\(x_3\\) に行って，\\(y\\) に至る経路です。これらを足し合わせて \\[\nx_1 と y \\ の相関 = a + (d \\times b) + (e\\times c)\n\\] となります。　\n\\((d \\times f \\times c)\\) もパスとしてはあるではないか，と思われるかもしれませんが（私は初見そう思った\\(\\cdots\\)），これは「双方向矢印は最大でも１つしか含められない」に抵触するため採用できません。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>パスモデル</span>"
    ]
  },
  {
    "objectID": "path1.html#パス係数の値",
    "href": "path1.html#パス係数の値",
    "title": "5  パスモデル",
    "section": "5.5 パス係数の値",
    "text": "5.5 パス係数の値\n同様（ぜひ確認してみましょう）にして，各独立変数と従属変数の相関係数について以下が得られます。 \\[\\begin{align*}\nx_1 と y \\ の相関 = a + (d \\times b) + (e\\times c)\\\\\nx_2 と y \\ の相関 = b + (d \\times a) + (f\\times c)\\\\\nx_3 と y \\ の相関 = c + (f \\times b) + (e\\times a)\n\\end{align*}\\]\n4変数の相関係数行列から \\[\\begin{align*}\n0.78 = a + (0.66 \\times b) + (0.68 \\times c)\\\\\n0.53 = b + (0.66 \\times a) + (0.60 \\times c)\\\\\n0.50 = c + (0.60 \\times b) + (0.68 \\times a)\n\\end{align*}\\] となり，\\(a=0.80\\)，\\(b=0.05\\)，\\(c=-0.07\\) を得ます（以下のコード参照）。\n\n\nCode\nvec_r &lt;- c(0.78, 0.53, 0.50)\nmat_c &lt;- rbind(\n    c(1.00, 0.66, 0.68),\n    c(0.66, 1.00, 0.60),\n    c(0.68, 0.60, 1.00)\n)\n# 逆行列を求める\nsolve(mat_c, vec_r) |&gt; round(2)\n\n\n[1]  0.80  0.05 -0.07\n\n\nつまり，「親の収入（\\(x_1\\)）」と「達成度（\\(y\\)）」の相関は，\\(x_1\\)の直接的な影響\\(a\\)と，「学業成績（\\(x_2\\)）」を経由して与える影響\\((d\\times b)\\)と，「向上心（\\(x_3\\)）」から伝わる影響\\((e\\times c)\\)を合わせたものとして表現された（相関をモデル化した）ということがわかります。実際， \\[\\begin{align*}\nx_1 と y \\ の相関 =&\n0.80 + (0.66 \\times 0.05) +\n(0.68 \\times (-0.07))\\\\\n=&0.80 + 0.033 - 0.0476=0.7854\n\\end{align*}\\] となり，丸め誤差はありますが相関係数が復元されます。\n同様に，\\(x_2\\) と \\(y\\) の相関は\\(0.536\\)，\\(x_3\\)と\\(y\\)は\\(0.504\\)です。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>パスモデル</span>"
    ]
  },
  {
    "objectID": "path1.html#決定係数",
    "href": "path1.html#決定係数",
    "title": "5  パスモデル",
    "section": "5.6 決定係数",
    "text": "5.6 決定係数\n先に，「パス図において，２つの変数または１つの変数に注目し，その変数に至るパスを辿って，各パスの係数を掛け，可能なパスすべての結果を足し合わせる」ことをトレーシングルールとして示しました。\n従属変数 \\(y\\) について，\\(y\\) 自身に至るパスを考えてみましょう。自分との共分散（相関）ですから，すなわち \\(y\\) の分散（標準偏差）です。\n順行するまでは逆行できるので，\\(x_1\\) に行って \\(y\\) に戻ってくる経路 \\(a \\times a\\) がまず考えられます。\\(b^2\\)，\\(c^2\\) も同様です。\nまた，\\(y\\) から \\(x_1\\) に行って \\(x_2\\) に渡って \\(y\\) に戻ってくる，すなわち \\((a\\times d \\times b)\\) のパスがあります。これは \\(b\\rightarrow d \\rightarrow a\\) の順でもOKです。したがって \\(2adb\\) となります。\n誤差項のパスもあります。誤差に逆行してぐるっと回って \\(y\\) に戻る \\((1 \\times g \\times 1)\\) の経路です。\n以上から \\[\\begin{align*}\ny\\ の分散=\na^2 + b^2 + c^2 + 2(adb) + 2(aec) + 2(bfc) + g\n\\end{align*}\\] です。標準化しているので \\[\\begin{align*}\n1.00=\n(0.80)^2 &+ (0.05)^2 + (-0.07)^2 + \\\\\n&2(0.80\\cdot 0.66\\cdot 0.05) + 2\\cdot (0.80\\cdot 0.68 \\cdot (-0.07)) + \\\\\n&2\\cdot (0.05 \\cdot 0.60 \\cdot (-0.07)) + g\n\\end{align*}\\] が得られ，ここから \\[\\begin{align*}\n1.00=0.62+g\\\\\ng=0.38\n\\end{align*}\\] と求めることができます。標準化された状況での（予測）誤差の分散ですから，逆に従属変数 \\(y\\) の分散説明率，すなわち決定係数 \\(R^2\\) は \\[\nR^2=0.62\n\\] であることがわかります。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>パスモデル</span>"
    ]
  },
  {
    "objectID": "path1.html#section",
    "href": "path1.html#section",
    "title": "2  パスモデル",
    "section": "2.7 ",
    "text": "2.7",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>パスモデル</span>"
    ]
  },
  {
    "objectID": "path1.html#r-による分析",
    "href": "path1.html#r-による分析",
    "title": "5  パスモデル",
    "section": "5.8 R による分析",
    "text": "5.8 R による分析\n\n5.8.1 相関係数行列の入力\nパスモデル（SEM）の枠組みでの分析には，Rのパッケージlavaan（la tent va riable an lysis）を使用します。\nまず，相関係数行列を読み込みます。lavaanの関数lav_matrix_lower2full()を利用すれば， 下三角行列の状態で入力しても問題ありません。 データフレームでなくても，行名と列名を付すことで分析データとして使用できます。\n\n\nCode\nrequire(lavaan)\n\n\nLoading required package: lavaan\n\n\nThis is lavaan 0.6-19\nlavaan is FREE software! Please report any bugs.\n\n\nCode\nmat_cor &lt;- lav_matrix_lower2full(\n  c(1.00,\n    0.66, 1.00,\n    0.68, 0.60, 1.00,\n    0.78, 0.53, 0.50, 1.00))\nvec_vnames &lt;- c(\"x1\", \"x2\", \"x3\", \"y\")\nrownames(mat_cor) &lt;- vec_vnames\ncolnames(mat_cor) &lt;- vec_vnames\nprint(mat_cor)\n\n\n     x1   x2   x3    y\nx1 1.00 0.66 0.68 0.78\nx2 0.66 1.00 0.60 0.53\nx3 0.68 0.60 1.00 0.50\ny  0.78 0.53 0.50 1.00\n\n\n上のように，分析対象の相関係数行列を用意できました。\n\n\n5.8.2 モデル式\n続いてモデル式を記述します。\n\n\nCode\nmdl_path_multireg &lt;- '\n  y ~ a*x1 + b*x2 + c*x3 # 重回帰モデル\n  # 以下4行は記述しなくても本来は支障なし\n  # 誤差分散と独立変数間の共分散にラベル付け\n  # いずれもlavaanは自動的に設定するため\n  # 分析者が明示的に記述する必要はない\n  y ~~ g*y\n  x1 ~~ d*x2\n  x1 ~~ e*x3\n  x2 ~~ f*x3\n'\n\n\n1行目がモデル式のオブジェクト名で，代入の&lt;-の後に引用符’ ’が続いています。 つまり，文字列としてモデルを記述しているということです。 二重引用符” “でも同じです。\n切片を含む重回帰モデルの式 \\[y = i + ax_1+bx_2+cx_3+誤差\\] に対して，Rでの変数名がそれぞれy, x1, x2, x3に対応しているとき，式はy ~ 1 + x1 + x2 + x3と表します。関数lm()の表記と共通していますが，\\(x\\) によって \\(y\\) が予測，説明されるとき，y ~ xのように記述します。\n係数 \\(a\\)，\\(b\\)，\\(c\\) を書く必要はありません。また，誤差項の記述も不要です。\n ~ 1は定数，平均，切片を表す記法です。ただし，ここでは標準化したデータを考え，切片項の \\(i\\) は扱わない \\(y = ax_1+bx_2+cx_3+誤差\\) を考えているので，上記2行目に ~ 1の記述はありません。\nコメントでも示しましたが，記号*はパラメータにラベルを付けるための印です。まず，誤差分散は （lavaanが自動的に設定してくれますが）y~~yと表します。  ~~ が分散・共分散の表記です。変数 \\(y\\) と \\(y\\)，つまり自分自身との共分散なので分散，しかもここでは誤差変数の分散を表すことになります。\nその上で，g*を間に挟み，この誤差分散にgというラベルを付けています。以下，x1~~d*x2なども同様です。パス図で示したアルファベットと対応するようにラベルを付しています。\nlavaan()では，モデルで直接推定される係数以外に，モデル内のパラメータを使って新しいパラメータを定義することができます。このモデルにはありませんが，間接効果を定義可能です。記号は := を使います。例えば，親の収入 \\(x_1\\) の多寡が学業上の向上心 \\(x_2\\) を変化させ，その影響が達成度 \\(y\\) に及ぶ，というモデルの場合，各々のパス係数が \\(a\\) と \\(b\\) であった場合，y ~ a*x1 + b*x2 のように，パス係数にラベルをつけた上で， ind_eff := a * cのように記述します。ind_effは私がつけたラベルで，他でももちろんかまいません。また，a * cの*はラベル付けではなく，係数を掛け合わせて間接効果を表しています。\nまとめると，以下の通りです。 \n\n\n5.8.3 分析の実行\nパッケージlavaanには，その名と同じ，SEMの分析に汎用的に使える関数lavaan()がありますが，ここでは以下のように関数sem()を使って推定を行います。sem()はlavaan()のラッパー関数です。いくつかの引数が，ここでの分析に適切な形であらかじめ設定されています。詳しくは?sem()で確認しましょう。\n\n\nCode\nfit_path_multireg &lt;- sem(mdl_path_multireg,\n  sample.cov = mat_cor, sample.nobs = 100)\nsummary(fit_path_multireg, rsquare = TRUE)\n\n\nlavaan 0.6-19 ended normally after 18 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        10\n\n  Number of observations                           100\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  y ~                                                 \n    x1         (a)    0.797    0.094    8.464    0.000\n    x2         (b)    0.046    0.086    0.527    0.598\n    x3         (c)   -0.069    0.088   -0.784    0.433\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  x1 ~~                                               \n    x2         (d)    0.653    0.119    5.508    0.000\n    x3         (e)    0.673    0.120    5.623    0.000\n  x2 ~~                                               \n    x3         (f)    0.594    0.115    5.145    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .y          (g)    0.385    0.054    7.071    0.000\n    x1                0.990    0.140    7.071    0.000\n    x2                0.990    0.140    7.071    0.000\n    x3                0.990    0.140    7.071    0.000\n\nR-Square:\n                   Estimate\n    y                 0.611\n\n\nsem()（lavaan()）は，共分散行列（およびサンプルサイズ指定）か，またはデータフレームを分析対象として受け付けます。今回は引数sample.covとsample.nobsにそれぞれ4変数の相関係数行列と人数を指定しています。データフレームの場合は，引数dataに与えます。\n分析結果のオブジェクトを関数summary()に渡すと，何も指定しなければ主に以下が出力されます。\n\n推定が収束したか（最適計算が無事に終了したか）\n推定法\nサンプルサイズ\n適合度指標（\\(\\chi^2\\)統計量とその自由度および\\(p\\)値）\n非標準化解\n標準誤差\n推定値と標準誤差の比（Wald統計量）と\\(p\\)値\n\nlavaan()の推定結果用のsummary()の重要な引数は，\n\nstandardized\nfit.measures\nrsquare\nmodindices\n\nです。ここではrsquare=TRUEとし，従属変数の決定係数（のみ）を確認しましたが，基本的には上記4つすべてTRUEにしておきましょう。\n\n\n5.8.4 実習\n\n4変数の相関行列を使って以下のパス図の分析をしなさい。間接効果も定義し，検討すること。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>パスモデル</span>"
    ]
  },
  {
    "objectID": "path1.html#間接効果",
    "href": "path1.html#間接効果",
    "title": "5  パスモデル",
    "section": "5.7 間接効果",
    "text": "5.7 間接効果\n重回帰モデルしか分析手法がない場合とくらべて， パスモデルでは，例えば３つの変数の関係を以下のように表すことができます。\n\n\n\nこのように柔軟にモデル構成ができると，重回帰モデルにはなかったタイプの変数の影響を考えることができます。間接効果 （indirect effect）と呼ばれる波及効果です。 間接効果は，ひとつの影響が，他の変数を経由して複合的に及びます。 例えば，一番上の図の \\((a \\times b)\\) や一番下の \\((a \\times b)\\) が間接効果にあたります。",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>パスモデル</span>"
    ]
  },
  {
    "objectID": "R_basics1.html",
    "href": "R_basics1.html",
    "title": "2  Rの基礎",
    "section": "",
    "text": "2.1 共通語としてのR\n押井守監督による1989年のアニメーション『機動警察パトレイバー 劇場版』では，旧約聖書創世記11章から上記の語句が引用されます。 もうずいぶん前になりますが，院生だった頃の私が（映画館ではなく）テレビで観た『パトレイバー』の「バベルの塔」に関する上述のシーンは， 最新の基本ソフトウェアを導入した産業用ロボットが暴走する事件を描くこの映画の中でも，特に強く印象に残りました。\nというのも，その当時，統計解析用のソフトウェアやプログラミング言語としてSASやSPSS，MATLAB，MATHEMATICAなどに囲まれ， 講義によってはC言語などを使い，特定の統計モデルに関しては専用のソフトウェアの使用法をそれぞれ学ぶ必要がある中で， 先行研究の手法がSという言語で実装されていたため，さらに新しい言語を学ぶ必要に迫られていたからです。\n教科書の分析例や，統計のそれぞれの手法をバラバラの統計ソフト，言語で理解するのは困難が伴いました。 また，効率も悪く，拙い自分の乱れた言葉では分析が停止したり， ひどい時にはプログラムが暴走したりしてしまうことも少なくありませんでした。\n現在でも，社会科学の分野ではSPSSが広く普及しています（最近では清水先生のHADやJASPなども人気？）。 企業などではExcelが活用され，データを処理するソフトというとExcelを連想するのが一般的かもしれません。\nところが一方で，20年以上前から計量的な研究の領域やデータ解析の場面で， ひとつのアルファベットの文字が，特に強い関心を惹きつけてきました。 その文字とは，R，統計解析環境R言語です。 Rは現在，lingua franca（共通語）という表現が用いられるほど普及し， 分析に活用され，さらに発展を続けています。\nみなさんも，“… using R” や “… with R” といったタイトルや， 「Rによる〇〇」「Rで理解する□□」のような書名を見かけることが多いのではないでしょうか。 統計数理研究所の公開講座ではRを実習に活用する講義がほとんどですし， Rとは別のソフトウェアの使用を前提にしていた統計学の教科書が，R版に書き換えられる，といった変化も多く起こりました。 改訂版の序文では，その理由として，多くの大学でRの採用が進んでいること， Rは統計的手法を包括的に扱えることなどが挙げられています。\nNew York Timesでは，2009年の時点でGoogleや製薬会社のPfizer，Bank of Americaといった金融，Shellのようなエネルギー産業まで幅広い業種でR の利用が広がっている実態が取り上げられています。また，大学でのRの採用の拡大， 大学院修了生のRの習得の実態などが報じられています。 この記事自体に対する反響も大きく，記事発表の2日後には記者がブログで補足を行っており， Rに向けられた注目の高さを窺い知ることができます。\n機械学習や人工知能研究に強いPythonを好む人も多いとは思いますが， これまでの動向を考えると，Rを知ることは手法の学習や研究，実用など様々な場面で効率性， 生産性を向上させ，非常に有効であると考えられます。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**R**の基礎</span>"
    ]
  },
  {
    "objectID": "R_basics1.html#共通語としてのr",
    "href": "R_basics1.html#共通語としてのr",
    "title": "2  Rの基礎",
    "section": "",
    "text": "いざ我等降り，彼処にて彼等の言葉を乱し，互いに言葉を通ずることを得ざらしめん。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**R**の基礎</span>"
    ]
  },
  {
    "objectID": "R_basics1.html#rとは何か",
    "href": "R_basics1.html#rとは何か",
    "title": "2  Rの基礎",
    "section": "2.2 Rとは何か",
    "text": "2.2 Rとは何か\n\n2.2.1 言語であり環境\nRでは，想像し得るあらゆることを実現可能である，と述べる人もいます。Rは効率的なデータ操作，行列の形式にも強い計算機能，統合的かつ豊富なデータ解析手法，さらに，データの分析や表示のためのグラフィクスやプログラミング言語としての機能を備えた汎用的で統合的なアプリケーションソフトウェアです。UNIXやmacOS，Windowsなど多様なオペレーティングシステム上で使用することができます。\n高機能なRは，その一方で，ソースコードを全面的に公開し，自由に複製，配布，改変が可能であるという特徴を持っています。つまり，どのような仕組みで動いているのかを完全に把握できるRを無料で入手し，利用できるということです。このオープンソースとしてのRの特徴は，自発的で，分散的かつ協働的な開発を促し，世界中の人々がRの発展に寄与する状況を生み，現在も改良が続けられています。\nRは更新の頻度が高く，年に2回，4月と10月に細かい機能を追加するなどのマイナーな更新が行われます。それ以外でも，主に小さな不具合の修正であるパッチでの更新が随時行われています。 また，R本体だけでなく，分析手法や他のソフトウェアとの連携など様々なRの拡張機能が多くの研究者などによって開発され，パッケージ（package）という形で入手可能となっています。このパッケージの充実ぶりを考えると，Rではあらゆることが可能であるという上述の意見も，あながち大げさとは言えない印象を受けます。\nRは，統計解析やグラフィクスのための言語であり環境であると表現されます。ここで環境（environment）という言葉は，Rが十分に計画された一貫した設計思想のシステムであることを示しています。\n\n\n2.2.2 Rの導入\nRはhttp://www.r-project.org/からダウンロードすることで入手可能です。実際のダウンロードの際には，CRAN（Comprehensive R Archive Network）と呼ばれるサイトから最寄りのミラーサイト（https://ftp.yz.yamagata-u.ac.jp/pub/cran/）を選択してダウンロードすることとなります。\nRは，オンライン上のマニュアルが充実しているだけでなく，ヘルプも役に立ちます（Rに限らないかも知れませんが）。 使い始めの最初のうち，Rの関数を使って処理を実行していく際に，何かわからないことや困ったことがあったら，ヘルプを参照するだけで解決されることが多々あります。 Rを使い慣れているつもりでも，ヘルプの関数の説明に新たな発見があることも珍しくありません。\nある関数の詳細を調べるだけでなく，目的の処理に対応する関数を見つける検索のための関数も存在します。指定した語句の全部，または一部を含む関数を探したり，曖昧なマッチングで検索したりすることが可能です。\nある関数が，実際どのように使用できるかのデモンストレーションを実行させたり，具体的な使用例を表示させる関数は，Rを実際的に理解するのに大変便利です。自分自身で入力し，結果を確認する作業の他に，これらの関数やヘルプを積極的に活用すると，Rで実際に何が可能なのかが，その実現方法とともに一目瞭然となり，理解が早く深まることが期待できます。\n\n\n2.2.3 関数\nRにおける関数（function）は，原則，引数（argument）を受け取り， 処理し，戻り値（return value）を返します。\nRでは，関数名(引数名=値)という形で様々な関数を用い， あるいはそれらを組み合わせ，時には自分で関数を作成して目的の処理を行っていきます。 関数の処理に具体的な内容を与えるのが引数です。 引数が複数の場合はカンマ（ ,）で区切ります。 なお，引数名を省略し，その値のみを記述する場合もあります。 また，特別な場合を除いて明示的に指定する必要のない引数や，そもそも引数を必要としない関数もあります。\n戻り値は原則ひとつですが，複数の結果を返したり，明示的な戻り値がない関数もあります。\n電子レンジに食品を温める機能（function）があるように， 関数は何らかの処理を機能として提供します。 例えば，関数（機能）電子レンジに 冷やご飯と温め時間を引数として渡すと， 電子レンジ(食材=冷たいごはん, 温め時間=2分) のように実行され，温められたごはんが手に入ります。\n同様に，以下のように正の平方根（sq uare r oot）を計算する 関数sqrt()の引数xに\\(9\\)を指定すると， 3という戻り値が得られます。\n\n\nCode\nsqrt(x = 9)\n\n\n[1] 3\n\n\n\n\n2.2.4 オブジェクト\n\n2.2.4.1 ラベルの付いた容器\n少し（退屈な）遠回りになりますが，Rにおけるオブジェクト（object）の考え方を紹介します。\nRで扱う「対象」は全て一括りにオブジェクトと呼ばれます。 Rでは，数値に限らず文字列や関数，詳細な統計解析結果などを，作業スペース（working space）と呼ばれるRの環境にオブジェクトとして格納できます。 作業スペースとは，その名の通りRの作業台です。 皆さんが勉強するときの「机の上」に例えることができます。 机の上の教科書やノート，参考書などがオブジェクトで，全体として「勉強環境」が構成されていると考えてください。\nRでは，名前が付いたオブジェクトの集合体であるフレーム（frame）によって環境が構成されます。環境という概念の導入によって，大量のオブジェクトを扱う巨大で複雑なプロジェクトも，混乱なく効率的に扱うことが可能になります。\nオブジェクトはよく「ラベルがついた箱」に例えられます。 何でもいれられる箱，容器のようなイメージです。　\n以下のように，ラベルを付けてRにオブジェクトを作りましょう。オブジェクトへの値の代入，あるいは付値（assignment）と呼ばれる作業です。\n\n\nCode\n# ← このシャープ記号はコメント開始の合図\n# この記号以降は改行までRには一切無視される\n# 以下のpiに3を代入するのは説明のためのダメな例です\npi &lt;- 3 # !!! piはRにもともと組み込まれている定数のラベル\n# piというラベルのオブジェクトの内容を確認 print する \nprint(pi) # pi とだけ入力してもprint(pi)と同じ\n\n\n[1] 3\n\n\nオブジェクトへの付値は，&lt;-を用いて行います。不等号記号とマイナス記号との間にスペースを入れないよう注意しましょう。5行目のように，関数print()で ( )内に指定したオブジェクトの中身，内容を表示させることができます。なお，オブジェクト名だけを入力しても同じです。ここでは，3が代入されていることが確認できます。\nまた，記号#はコメントの開始を表し，以降改行まで無視されます。\nオブジェクト名には大文字または小文字のアルファベット，数字，ピリオド（.），アンダースコア（_）が使われます（日本語も使用可能ですが，オブジェクト名としてはオススメしません）。自分で付値するオブジェクト名の先頭はアルファベットとします。ピリオドやアンダースコアはオブジェクト名の分かりやすさを高めるために使用されます。 Rは大文字と小文字を区別するので注意しましょう。 なお， break， else， for， function， if， in， next， repeat， return， file， TRUE， FALSEは， R において特別な機能を付された予約語であり，オブジェクト名には使用できません。\n\n\n2.2.4.2 オブジェクトの属性\nオブジェクトは容器のようであるとお伝えしましたが， 中に何が入っているか，いわばタグ付けされていて 非常にわかりやすいというのが便利なところです。\nオブジェクトには，属性（attribute）があります。 属性によってそのオブジェクトの特徴，性質を表し，適切な処理が行われます。 例えば，以下の計算がそれを端的に示しています。\n\n\nCode\none &lt;- 1; two &lt;- 2; three &lt;- 3 # ;で区切ると1行に複数の命令を記述できる\none + two + three\n\n\n[1] 6\n\n\n\n\nCode\n# 引用符 ' ' または \" \" は文字列を表す\nun &lt;- 1; doux &lt;- 2; trois &lt;- \"3\"\nun + deux + trois\n\n\nError: object 'deux' not found\n\n\nオブジェクトtroisは文字列として“3”が格納されているので， これを1や2が入ったオブジェクトun，deuxと足すという演算は意味を成しません。 それがエラーに示されています。 これは，オブジェクトの「タグ付け」のうち，モード（mode）と呼ばれる属性に関わる問題です。\n\n\n2.2.4.3 モード\nモードは，オブジェクトの属性の中でも，長さ（length）とともに本来的なものとされます。 データ分析で重要になるモードの種類は，以下の3つです。\n\nnumeric ：数値型（整数 integer と倍精度 double の両方を含む）\ncharachter ：文字列型\nlogical ：論理型\n\nオブジェクトのモードが何であるかは，関数mode()で確認することができます。\n\n\nCode\nmode(one)\n\n\n[1] \"numeric\"\n\n\nCode\nmode(trois)\n\n\n[1] \"character\"\n\n\nCode\nmode(TRUE)  # Rにおける「真」「偽」はそれぞれ大文字TRUEとFALSE\n\n\n[1] \"logical\"\n\n\nCode\n# 関数c() はcombine, concatenateのc\n# 要素を並べてベクトルにする\nvec_num_logi &lt;- c(1, 2, 3, TRUE, FALSE)\nvec_num_logi\n\n\n[1] 1 2 3 1 0\n\n\n6行目の中身をRに出力すると，論理型であるTRUEとFALSEが， それぞれ\\(1\\)と\\(0\\)に変換されていることに注意しましょう。\n\n\nCode\nmode(vec_num_logi)\n\n\n[1] \"numeric\"\n\n\nこのベクトルのモードは数値型です。つまり，ベクトルは単一種類のモードしかとり得ず， 異なるモードの要素が含まれる場合，強制変換されます。 例えば，文字列と数値をベクトルとして並べれば，数値は文字列に変換されます。\nオブジェクトが，ある特定のモードであるかどうかを判定するには， abcをそのモード名として，関数is.abcを用います。\n\n\nCode\nis.logical(one)     # --- オブジェクト one は論理型ですか？\n\n\n[1] FALSE\n\n\nCode\nis.character(one)   # --- 文字型ですか？\n\n\n[1] FALSE\n\n\nCode\nis.numeric(one)   # --- 数値型ですか？\n\n\n[1] TRUE\n\n\nなお，中身が空の，つまり長さ0のベクトルを作成することも可能であり，そのオブジェクトにもモードが付与されます。\n\n\nCode\nvec_empty &lt;- c()  # --- 関数c()の中身が何も無く，空っぽ\nvec_empty         # --- オブジェクト内容の表示\n\n\nNULL\n\n\n\n\nCode\nlength(vec_empty) # --- オブジェクトの「長さ」を表示\n\n\n[1] 0\n\n\n\n\nCode\nmode(vec_empty)   # --- 空（から）のオブジェクトのモード\n\n\n[1] \"NULL\"\n\n\nNULLは空値，ヌル値と呼ばれ， オブジェクトvec_empyの中身が空っぽであることを表します。 length()という関数は，オブジェクトの「長さ」を返します。 オブジェクトによって，長さという表現が必ずしも最適ではないので，ここでは「長さ」と表記しています。 ベクトルの場合，length()が返すのは要素の数です。 要素はありませんので，0と表示されています。 ここではモードも“NULL”です。\n\n\n2.2.4.4 クラス\nモードというオブジェクトの属性は，数値か文字かといった基礎的な特徴を表していました。 基礎的であるだけに重要な区別ですが，より進んだ分析においては汎用性，抽象性が高過ぎることも否めません。 これに対して，オブジェクトにはクラス（class）という属性も存在します。\nモードが，例えば「本」という抽象化の水準とするならば， クラスは「教科書」，「参考書」，「マンガ」程度の抽象化と考えることができます。 以下の具体例で，クラスという概念を導入する利点を確認してみましょう。\n8月25日の金曜日から，9週分の金曜日の日付を表示します。\n\n\nCode\nweekdays(\"2025-8-25\")\n\n\nError in UseMethod(\"weekdays\"): no applicable method for 'weekdays' applied to an object of class \"character\"\n\n\n関数weekdays()は曜日を返す関数です。 モードが文字列（ここではcharacterというクラスでもある）である“2025-08-25”には 曜日も何もありませんから，当然エラーが返されます。\n\n\nCode\nday1 &lt;- as.Date(\"2025-8-25\") # --- 文字列\"2025-8-25\"を日付として変換\nweekdays(day1)\n\n\n[1] \"Monday\"\n\n\n関数as.Date()は，単なる文字列である“2025-08-25” を， Dateという日付クラスに変換します。 ある特定のモードabcの判定に is.abc() という関数があったように，特定のモード，あるいはクラスに変換する as.abc()という関数が用意されています。\n\n\nCode\n( vec_9weeks &lt;- seq(from=day1, length.out=9, by=\"1 week\") )\n\n\n[1] \"2025-08-25\" \"2025-09-01\" \"2025-09-08\" \"2025-09-15\" \"2025-09-22\"\n[6] \"2025-09-29\" \"2025-10-06\" \"2025-10-13\" \"2025-10-20\"\n\n\nseq()という関数は，規則的な（sequentialな）要素のベクトルを生成します。 8月25日（引数fromで指定）から1週間おき（引数by）に， 9週分（length.out）の日付を生成しています。\nオブジェクトvec_9weeksの特徴を調べてみましょう。 クラスを知るには，関数class()を用います。\n\n\nCode\nmode(vec_9weeks)\n\n\n[1] \"numeric\"\n\n\nCode\nclass(vec_9weeks)\n\n\n[1] \"Date\"\n\n\nCode\nstr(vec_9weeks)\n\n\n Date[1:9], format: \"2025-08-25\" \"2025-09-01\" \"2025-09-08\" \"2025-09-15\" \"2025-09-22\" ...\n\n\nモードはnumeric，すなわち数値であることが返されています。 しかし，ただの数字ではありません。そのクラスは“Date”です。 5行目のstr()は，様々なオブジェクトの構造を知るのに便利な関数です。\nでは，ここでvec_9weeksの平均を関数mean()を用いて計算してみましょう。\n\n\nCode\n( middle_day &lt;- mean(vec_9weeks) )\n\n\n[1] \"2025-09-22\"\n\n\n上記のように，2025-09-22が2025-08-25と2025-10-20の平均として計算されます。 このような処理こそ，Rが統合的な統計解析環境であると言われる所以です。 Dateというクラスに属しているオブジェクトに関数mean()が適用されると， このクラスの特徴に応じて，通常の算術平均を求める関数とは異なるmean.Date()という関数が使用されます。 実はseq()を日付に適用したときにも，同様のことが起こっていました。\n分析者は，数値の平均にはこの関数，日付の平均にはあの関数というようなことを意識する必要はありません。 適切にオブジェクトを扱っていれば，適切な方法が選択されるようにRは設計されています。\nなお，モードやクラスを判定する関数is.abc()や， あるモードやクラスに変換するas.abc()には， 以下のコードで出力されるように様々なものがあります。\n\n\nCode\napropos(\"^is\\\\.\") # 出力は省略\napropos(\"^as\\\\.\") # 出力は省略\n\n\n\n\n\n2.2.5 環境\npi &lt;- 3とした付値において ダメな例であるとコメントを付したのは， piはRがすでに使用しているオブジェクト名だからです。この代入の後，以下の計算をすると，期待される答え\\(-1\\)が返ってきません。\n\n\nCode\ncos(pi) # --- pi には3 が格納されている\n\n\n[1] -0.9899925\n\n\nオブジェクトを取り除くには，関数rm() またはremove() を使用します。\n\n\nCode\nrm(pi) # --- remove(pi) としても同じ\nls()   # --- 作業スペース内のオブジェクトの表示 # objects() としても同様\n\n\n [1] \"day1\"         \"doux\"         \"middle_day\"   \"one\"          \"three\"       \n [6] \"trois\"        \"two\"          \"un\"           \"vec_9weeks\"   \"vec_empty\"   \n[11] \"vec_num_logi\"\n\n\n1行目でオブジェクトpiを削除しています。 2行目のls()という関数は， 作業スペースに存在するオブジェクト名を返す関数です。 出力にpiは見当たらず，作業スペース環境から 中身が3であるpiというラベルのオブジェクトは消去されたことが確認できました。\nところが，以下のようにpiというラベルの オブジェクトの中身を確認することができ，その値は円周率であることが確認できます。\n\n\nCode\npi # --- 削除を確認したはずのpiの表示\n\n\n[1] 3.141593\n\n\nrm(pi) という命令は，Rに元々組み込まれた pi まで削除した訳ではないことがわかります。 これは，Rの「環境」という考え方を表すものです。\n3を代入したpiは， 作業スペースと呼ばれる環境にありました。 これは，大域的環境（global environment）と呼ばれる環境です。 最も上層で優先される場所になっています。 一方，組み込みのpiは， baseと呼ばれる環境に存在します。 作業スペースにあったpi というオブジェクトが無くなったので， baseのpiの値が表示される結果となりました。 なお，base環境にあるオブジェクトを消去することはできません。\n環境について，次のように確認してみましょう。\n\n\nCode\n# ( )でくくるとオブジェクト生成と同時に内容を表示\n(pi &lt;- 3)                                      # --- pi に3 を代入\n\n\n[1] 3\n\n\nCode\nls.str(envir=.GlobalEnv, pattern=\"^pi\")        # --- 作業スペースのpi\n\n\npi :  num 3\n\n\nCode\nls.str(envir=.BaseNamespaceEnv, pattern=\"^pi\") # --- base のpi\n\n\npi :  num 3.14\npipe : function (description, open = \"\", encoding = getOption(\"encoding\"))  \n\n\n上では関数ls()ではなくls.str()を使用しています。 これによって，引数envir で指定した環境内にあるオブジェクト名と，その構造（structure）も同時に表示させることができます。 構造とは，オブジェクトの特徴を示したものです。 なお，引数envirに何も指定しなければ，そのデフォルト（既定値）である作業スペースが対象となります。\n.GlobalEnvと.BaseNamespaceEnvは，それぞれ大域的環境（作業スペース）とbase環境を表すRのオブジェクトです。つまり，環境もRの中ではオブジェクトとして扱われます。\n作業スペースにあるpiは， 自分で付値した3であることがpi:num 3 という表示で示されています。 base環境内ではpi:num 3.14であり， それぞれの環境で異なるpi が存在することがわかります。 勉強机と食事用テーブルは，はっきり区別されているわけです。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**R**の基礎</span>"
    ]
  },
  {
    "objectID": "R_basics1.html#enjoy",
    "href": "R_basics1.html#enjoy",
    "title": "2  Rの基礎",
    "section": "2.3 Enjoy!",
    "text": "2.3 Enjoy!\n先述したRのデータ操作や計算，描画などの機能は，有機的に連携させることが可能です。例えば，回帰分析の出力結果を用いて，今度はそれを図示すること，あるいは次の段階の詳細な分析に利用することなども容易です。\n回帰分析のRでの実行方法は，わずかな変更で一般化線形モデルにも適用できます。また，要約のための関数をひとつ覚えることで，多岐にわたる手法の様々な分析結果も，内部での違いをほとんど意識せずに同様に使用することができます。このことは，データの特徴（より細かくは変数の種類など）に応じた適切な処理，分析手法の選択が行われることを意味します。\nそもそもRは，「統合的な考え方に基づき，洗練され，広く認められた揺るぎないソフトウェアシステム」として1998年にThe Association for Computing MachineryのSoftware System Awardを受賞したS言語に基づいています。Sはそれまでのデータの扱い方，分析の仕方，視覚化の方法を決定的に変えたと言われる優れたシステムです。そのようなソフトウェアを設計の根幹に置くRによって，統計解析の様々な要素を総合的に扱えることは，データを詳細に分析し，分析した結果を使って次の分析に繋げるといった対話的，逐次的，探索的なデータ解析を可能にします。グラフィクスなども併用しながら，データから広く深く知見を導くことができる統一的な操作環境は，定型的で固定的なソフトウェアの出力に飽き足らない分析者にとって，理想的であると言えるでしょう。\nしかし一方で，Rの柔軟性は，分析者が何をどうしたいのかという目的を明確にし，何をしているのかという分析の実質を把握する必要性を，より高めることも意味します。基本的には，入力画面に関数と呼ばれる命令を入力することで処理を実行していくRでは，ある程度のプログラミングの知識，技術が必要となります。視覚的に分かりやすいインターフェイス上で，マウスなどのクリックによって高度な分析も実行可能なソフトウェアに比べると，「学習曲線が急峻である」「敷居が高い」などと言われる所以のひとつです。\nしかし，Rを使用するために必要な資格（ライセンス）に特別なものはいりません。それは関数license()の実行で表示される言葉に象徴されています。\n\nShare and Enjoy.\n\nデータ解析を楽しみながら学べる，研究できる，使える環境こそRです。実際に使ってみて，その喜びを共有してください。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>**R**の基礎</span>"
    ]
  },
  {
    "objectID": "R_basics2.html",
    "href": "R_basics2.html",
    "title": "3  Rによるデータ分析",
    "section": "",
    "text": "3.1 データの読み込み\nじゃんけんのデータを作成しましょう。 データSEMdai_Rock.xlsxには， 私が（実際はRの関数sample()が）30回のじゃんけんで出した手が入力されています。\nこれをダウンロードし，自分と書かれた列に 出した手を入力しましょう。\n入力できたらデータをRに読み込みます。 そのために，作業ディレクトリ（working directory）と パッケージ（package）について紹介します。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Rによるデータ分析</span>"
    ]
  },
  {
    "objectID": "R_basics2.html#作業ディレクトリ",
    "href": "R_basics2.html#作業ディレクトリ",
    "title": "3  Rによるデータ分析",
    "section": "3.2 作業ディレクトリ",
    "text": "3.2 作業ディレクトリ\nRには，作業スペース（working space）という考え方がありました。 「環境」とも呼ばれるここにオブジェクトを登録したり，ここから呼び出したりして分析作業を進めていきます。\n同様に，作業ディレクトリ（working directory）では，ファイルにデータを書き込んだり，ファイルから読み込んだりすることができます。ディレクトリはフォルダと同義です。 明示的に指定しなければ，Rがデータファイルなどを探すのは，この作業ディレクトリです。作業スペースが勉強机だとしたら，作業ディレクトリは「机の引き出し」に例えることができます。隠していたマンガ本を取り出したり，作成したノートをしまったりする場所です。\n作業ディレクトリの場所を確認するには以下のようにします（macOSを想定）。\n\n\nCode\n# get working directory\ngetwd()           # --- 現在の作業ディレクトリの確認\n\n\n[1] \"/Users/inanity/GitVS/SEMdai\"\n\n\nCode\n# 作業ディレクトリの変更\nsetwd(\"~/Downloads\") # ~で表されるホームディレクトリの下のダウンロードフォルダ\ngetwd()           # --- 再確認\n\n\n[1] \"/Users/inanity/Downloads\"\n\n\n作業ディレクトリに読み込みたいデータのファイルがあれば， “SEMdai_Rock.xlsx”のようにファイル名を指定するだけでOKです。 もちろん，コンピュータ内の正確な場所を指定すれば， 作業ディレクトリがどこであっても読み込み可能です。\n\n\nCode\nflnm &lt;- \"~/Downloads/SEMdai_Rock.xlsx\"  # フルパス\ntbl_j &lt;- readxl::read_xlsx(path = flnm) # これはズルで，本当は準備しないとエラーが出る",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Rによるデータ分析</span>"
    ]
  },
  {
    "objectID": "R_basics2.html#パッケージの利用",
    "href": "R_basics2.html#パッケージの利用",
    "title": "3  Rによるデータ分析",
    "section": "3.3 パッケージの利用",
    "text": "3.3 パッケージの利用\nデータはcsv（comma separated values）形式で配布されることが多く， 各値がカンマで区切られただけのcsvファイルの方が，テキストファイルとして メモ帳などでも開けるのでいいのですが，私が文字化けの問題に疲れ果てた感があり， Excelを利用してしまっています。\nRは，そのままでは拡張子xlsxのExcelファイルを扱えません。 そこで利用するのがパッケージ（package）です。 パッケージは，Rの機能を拡張する関数やデータのまとまりです。 導入するとそれまで不可能，あるいは非常に煩雑であった処理を実行可能になります。 ここでは，Excelファイルを読み込めるようになるreadxlを使います。\nパッケージを利用するために必要なことは２つ，インストールと「起動」です。 パッケージを起動することは，「パッケージを読み込む」「パッケージを呼び出す」など のように言われることもあります。\n工場出荷時の状態のスマートフォンが元のRで，SNSツールやゲームなど， インストールするアプリがパッケージであると捉えるとよいでしょう。 スマホアプリ（パッケージ）のインストールは一度行えばOKですが， 利用するには都度，指でタップして起動（パッケージの呼び出し）を する必要があります。\nパッケージは以下のように簡単にインストール可能です。\n\n\nCode\n# パッケージをダウンロードするリポジトリの指定\noptions(repos = \"https://ftp.yz.yamagata-u.ac.jp/\")\nupdate.packages(ask = FALSE) # インストール済みパッケージのアップデート\n\n\nWarning: unable to access index for repository https://ftp.yz.yamagata-u.ac.jp/src/contrib:\n  cannot open URL 'https://ftp.yz.yamagata-u.ac.jp/src/contrib/PACKAGES'\n\n\nCode\n# readxl がインストールされているかどうか確認\n# 未インストールの場合にFALSEになるので，否定(!)してTRUEにし\n# if以下が実行されるようにする\nif(!require(readxl)){\n  install.packages(\"readxl\")\n  require(readxl) # readxlの読み込み\n}\n\n\nLoading required package: readxl\n\n\n関数require()は，library()と 同様に，引数にパッケージの名前を指定すると，そのパッケージを 呼び出す（起動する）ことのできる関数です。 すでにインストールされているパッケージの名称は， オブジェクトのラベルなので，引数に指定する際には 引用符はいりません（文字列として扱う必要がないため ［引用符で囲んでもよい］）。\nrequire()は， パッケージの読み込みに対するステータスに応じて， 真偽値を返し，失敗するとFALSEとなります。\nこれでパッケージreadxlが使えるようになり， 関数read_xlsx()でExcelファイルが読み込めます。なお，readxl::read_xlsx()という 記法は，パッケージreadxl全体を使用可能にしなくても，その中に含まれるread_xlsx()だけ 使えるようにするものです。\n改めてデータを読み込みます。\n\n\nCode\n# 今度は準備万端\n# read:: とパッケージ名を付けなくてよい\ntbl_j &lt;- read_xlsx(path = flnm)\n\n\nそれでは，じゃんけんの結果を集計してみましょう。\n\n\n\n\n\n自分\n勝ち\nあいこ\n負け\nTotal\n\n\n\n\nグー\n33.3% (3)\n33.3% (3)\n33.3% (3)\n30.0% (9)\n\n\nチョキ\n33.3% (3)\n44.4% (4)\n22.2% (2)\n30.0% (9)\n\n\nパー\n33.3% (4)\n16.7% (2)\n50.0% (6)\n40.0% (12)\n\n\nTotal\n33.3% (10)\n30.0% (9)\n36.7% (11)\n100.0% (30)\n\n\n\n\n\n\n\n\n自分\n勝ち\nあいこ\n負け\nTotal\n\n\n\n\nグー\n30.0% (3)\n33.3% (3)\n27.3% (3)\n30.0% (9)\n\n\nチョキ\n30.0% (3)\n44.4% (4)\n18.2% (2)\n30.0% (9)\n\n\nパー\n40.0% (4)\n22.2% (2)\n54.5% (6)\n40.0% (12)\n\n\nTotal\n33.3% (10)\n30.0% (9)\n36.7% (11)\n100.0% (30)\n\n\n\n\n\nパッケージjanitorを使いました。 同様の表を作れるでしょうか。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Rによるデータ分析</span>"
    ]
  },
  {
    "objectID": "R_basics2.html#物件探し",
    "href": "R_basics2.html#物件探し",
    "title": "3  Rによるデータ分析",
    "section": "3.4 物件探し",
    "text": "3.4 物件探し\nファイルkawauchi_0819.xlsxは， リクルート社が運営する物件情報サイトsuumo（東北版）から， 2025年8月19日18:13時点でのデータをダウンロードした結果です。\nsuumoのトップページから「賃貸」をクリックすると， 「通学・通勤時間から探す」という メニューがあります。この機能で 「通勤・通学先の最寄り駅」として「川内(宮城)」を選択し，「電車での所要時間」を「10分以内」 に設定，「乗換回数」は「こだわらない」で検索しました。\n検索時点では26,346件の物件が抽出されました。\n1ページに50物件を「建物ごとに表示」した状態で，1から71ページまで 以下の16のデータについて読み取った結果です（同じ建物に複数の賃貸物件（部屋）があるため， 「建物ごとに表示」の設定では，1ページに50物件の表示でも50部屋とは限らない）。\n\n同じ物件で情報が重複していた場合（物件名, 区, 地番, タイプ, 広さ, 階数, 家賃, 管理費が同じ物件は，ひとつだけ残した）や， 最寄駅までバスに乗る物件， 階数の表示が非標準的であった物件（3-5階など）を除外した結果， 4,095件の物件に関するデータとなりました。\n最寄駅に関わる情報は，物件の最寄駅として最大3つ表示される駅のうち，最初の1つを対象としましたが，川内駅まで0分で到着する物件もあるため，データについてみなさんに意見を伺いたいです。 なお，表示の規則の詳細は不明ですが，対象とした最初の最寄駅が徒歩距離（分単位）で最短というわけでは 必ずしもなさそうです。ただし，短い時間が最初に表示される傾向はあるように見受けられました。\nまた，階数には欠損値，欠測値（missing value）があります。 元の物件情報では表示が – となっていたデータです。おそらく戸建てだと思われます。 欠測値はExcelファイル上では空欄になっています。\n上記のデータを入力したExcelファイル kawauchi_0819.xlsx には， 1列目に，連番を示す「番号」を挿入しています。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Rによるデータ分析</span>"
    ]
  },
  {
    "objectID": "handling.html",
    "href": "handling.html",
    "title": "4  データハンドリング",
    "section": "",
    "text": "4.1 種族値分析編",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>データハンドリング</span>"
    ]
  },
  {
    "objectID": "handling.html#種族値分析編",
    "href": "handling.html#種族値分析編",
    "title": "4  データハンドリング",
    "section": "",
    "text": "4.1.1 tidyverseの世界\nデータ分析では，各変数の分布の特徴を捉え， 変数間の関連を検討し，情報を得ようとします。 また，変数の変換や新たな変数の追加などを頻繁に行います。\nここでは，pokemon.xlsxを分析しながら， パッケージtidyverseを利用して 効率的に分析を進める方法を確認しましょう。\n基本となる関数は以下の3つです。 1. select()：特定の変数を選択する 1. mutate()：変数を変換したり，新しい変数を追加したりする 1. summarize()：平均や標準偏差など，変数の要約結果を得る\n\n\n4.1.2 変数の取り出し\ntidyなtable状のデータフレームであるtibble形式のデータから変数を取り出すには，関数select()を使います。 抜き出したい変数の名前に引用符” “を付ける必要はありません。 取り出した結果もtibble形式であり， 指定した順に抜き出されるので，変数の並べ替えにも使えます。\n\n\nCode\nrequire(tidyverse)\n\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nrequire(readxl) # tidyverseと一緒にインストールされるが起動はされない\n\n\nLoading required package: readxl\n\n\nCode\nflnm &lt;- \"~/Downloads/pokemon.xlsx\"\ntbl_p &lt;- read_xlsx(flnm)\ncolnames(tbl_p)\n\n\n [1] \"ポケモン\"   \"HP\"         \"攻撃\"       \"防御\"       \"特攻\"      \n [6] \"特防\"       \"速さ\"       \"type1\"      \"type2\"      \"type2有無\" \n[11] \"高さ\"       \"重さ\"       \"捕獲\"       \"経験値\"     \"なつき数値\"\n[16] \"なつき度合\" \"メガ進化\"  \n\n\n\n\nCode\ntbl_p |&gt;\n  select(ポケモン, 速さ, HP)\n# 出力略\n\n\nここで|&gt;は%&gt;%と同じパイプ演算子です。baseの（追加のパッケージが不要な）Rで使用できます。\n変数を1つだけ，シンプルなベクトルとして取り出すには， 関数pull()を用います。 tibble形式のデータを受け取っても処理できない関数などに対して利用します。指定する変数は1つです。\n\n\n4.1.3 効率的な取り出し方法\n変数名を指定するのではなく，列の番号でも指定可能です。 また，select()には変数の選択に便利な「お助け(helper)」関数，補助関数が用意されており， 効率的に変数を取り出せます。 詳細は help(select)として[Useful functions]の項を 参照してください。\n\nstarts_with()：指定した文字列から始まる変数を取り出す\nends_with()：指定した文字列で終わる変数を取り出す\nmatches()： 指定の文字列（正規表現と呼ばれる特殊な指定も可）に合致する変数を取り出す\n記号 : ：あたかも数値列のように変数の 並びを表せる（select(HP:速さ)で6変数を選択可）\n記号 - マイナスを変数名の前に付けると除外できる\n\n\n\n4.1.4 データの変換\n918体のポケモンについて，それぞれの総合ステータスを求めましょう。 つまり，「HP」から「速さ」の値をポケモンごとに単純合計します。 データの変換には関数mutate()を使います。\n\n\nCode\ntbl_p2 &lt;- tbl_p %&gt;% \n mutate(total=HP+攻撃+防御+特攻+特防+速さ)\n\n\n記号&lt;-は右側を左側に格納する指示でしたが， 記号%&gt;%は右側へ左側を渡す 指示です。 つまり， データのオブジェクトtbl_p を関数mutate() に渡し，その結果をオブジェクトtbl_p2 に格納しています。\n2行目のmutate()では， 新しい変数totalを作成，定義 していますが， これは引数ではなく変数名なので，例えば「総合」にしたり 「種族値合計」にしたり好きに設定できます。\n変数totalはHPから速さを足したものです。 パイプ演算子%&gt;%によってデータが mutate() に渡されているので，引用符なしで計算式を直接記述しています。\n\n\n4.1.5 偏差値での検討\n数学と英語の成績を比較する際に偏差値がよく使われるのは， 数学と英語の平均点が同じとは限らず，数学の80点と英語の 80点を同じ「80」として比較できないからです。 また，散らばりの大きさも異なる可能性があるので， 1点の差が数学と英語で同じ保証もありません。 数学の最低点が79点，最高点が81点， 英語では最低点が5点，最高点95点のときの1点の違いを想像してみてください。\nポケモンデータでも同じことがいえます。 「HP」と「攻撃」をそのままの値で比較するのは，数学と 英語の成績を直接比べるようなものです。そこで， 標準得点（standard score） の考え方でデータを見直してみましょう。\n標準得点は，データを特定の平均と 散らばり（分散，または標準偏差の値）に変換し， 目盛(scale)を統一する標準化(standardization)の結果 として得られる値です。 データ分析においてよく使われるのは，平均を0，標準偏差を1とした 標準得点です。 平均を引いて，標準偏差で割ることで，数学も英語も「HP」も 「攻撃」もすべて平均0，標準偏差1に目盛が揃ったデータになります。\n偏差値も標準得点の1つです。 平均0，標準偏差1の標準得点を10倍し，50を足すと偏差値になります。 小数点以下の細かい表示を10倍して回避し，50を足して マイナスの値を解消しています。もともと平均が0，標準偏差が1だったので， 偏差値の平均は50，標準偏差は10です。\nでは，偏差値を計算する関数を作ってみましょう。\n\n\nCode\ncalculate_Hscore &lt;- function(x){\n  z &lt;- (x - mean(x)) / sd(x)\n  h &lt;- z * 10 + 50\n  return(h)\n}\n\n\n自作の関数calculate_Hscore()では， 引数xにデータを指定します。 xは2行目で平均が引かれ，標準偏差で割られるので， 平均0，標準偏差1に標準化されます。 それを10倍して50を足した結果をhとして格納し， 関数return()で結果を返すようにしています。\nこの関数を利用して，関数mutate()によるデータの変換を 以下のように行えば，数量データについて一括して 偏差値を計算可能です。 変数の指定にあたっては，関数across()では select()と同じように，tidy-selectと呼ばれる 変数選択のための補助関数など便利な機能が使用できます。\n\n\nCode\ntbl_p3 &lt;- tbl_p2 |&gt;\n  mutate(across(HP:速さ, ~{\n    calculate_Hscore(.)\n  }))\n# tbl_p3\n\n\n上記の書き方では， 元の変数の内容が変更されますが， オリジナルの変数の値を保持しておきたい場合は across()の引数.names を利用して，例えば以下のように記述します。\n\n\nCode\ntbl_p2 |&gt;\n  mutate(across(HP:速さ, ~{\n    calculate_Hscore(.)\n  }, .names = \"{.col}_h\"))\n# 出力略\n\n\nこれにより，元の変数名それぞれに自動的に_hが付されます。 もちろん，_hの部分は好きな文字列で構いません。\n“{.col}_h”の{.col}は， 文字列表示に関わるglueというパッケージが 提供する記法で，変数名を表します。\nacross()によって各変数に適用したい処理は， 通常の関数の使用と同様にカッコを付し，ドットを指定します。 ただし，関数の前に ~ が必要です。\n各偏差値を合計した結果と「HP」などの値をそのまま合計した総合ステータスには どのような違いがあるか，モンスター分析編で検討する準備として， ここでは偏差値の合計を計算し，新たな変数h_total を作成しておきましょう。\n\n\nCode\ntbl_h &lt;- tbl_p2 |&gt;\n  mutate(h_total=HP+攻撃+防御+特攻+特防+速さ)\ntbl_h |&gt; select(ポケモン, total, h_total)\n\n\n# A tibble: 918 × 3\n   ポケモン        total h_total\n   &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;\n 1 フシギダネ        318     318\n 2 フシギソウ        405     405\n 3 フシギバナ        525     525\n 4 メガフシギバナ    625     625\n 5 ヒトカゲ          309     309\n 6 リザード          405     405\n 7 リザードン        534     534\n 8 メガリザードンX   634     634\n 9 メガリザードンY   634     634\n10 ゼニガメ          314     314\n# ℹ 908 more rows",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>データハンドリング</span>"
    ]
  },
  {
    "objectID": "sem1.html",
    "href": "sem1.html",
    "title": "6  潜在変数モデル",
    "section": "",
    "text": "6.0.1 背景\n構造方程式モデル（SEM）は観測変数と観測されない潜在変数（構成概念）間の複雑な関係性を同時に分析する多変量統計手法です。 汎用的なモデル表現によって，多くの統計モデルを下位モデルとして包摂します。\n因子分析と重回帰分析という2つの主要な多変量手法を統合しており，理論モデルを検証することが主な目的です。\n観測不能な概念（例：幸福感，計算能力）をモデルに組み込むことが可能であり，測定誤差を明示的に考慮できる点にも特徴があります。何より，潜在変数を含む変数間の相互依存関係を同時に評価できる点に強みがあります。\n\n\n6.0.2 SEMの発展\nアメリカの遺伝学者Sewall Wrightが1918年にパス解析を開発し，当初は遺伝形質の継承パターンを分析するために利用されました。変数間のつながりを相関係数として定義し，グラフィカルモデル（パス図）を使用しました。\n一方，Charles Spearman（1904年）やLouis Leon Thurstone（1935年）らが心理測定の領域で因子分析を開発しました。観測変数群の背後にある潜在的な「因子」を特定する手法です。これにより，知能や性格特性などの抽象概念の定量化が可能になります。\nそして，経済システム内の複雑なネットワーク関係をマッピングする手法として主流となる，変数間の同時方程式モデルが経済学分野で開発されます。\nパスモデル，因子分析，計量経済学の同時方程式モデルが統合され，観測変数と潜在変数の両方を含む複合的な分析が可能になりました。\n\n\n6.0.3 社会科学における潜在変数の必要性\n社会科学の研究者の課題として，幸福感や購買意欲，景気，適性，能力など直接観測できない多くの抽象的な構成概念をモデル化する必要性が挙げられます。\n1930年代，回答者の意見の方向性と強度を評価し，社会調査に広く採用されることとなるリッカート尺度 (Likert Scale)が開発されます。\n観測不能な量（潜在変数）を複数の観測可能な代理変数，指標変数を通じて測定する「三角測量」のアプローチが確立されました。\n\n\n6.0.4 SEMの普及と多様化\nソフトウェアの発展はめざましく，商用のソフトウェアとして， LISREL，AMOS (IBM-SPSS) といったグラフィカルユーザーインターフェースを備えたソフトウェアが登場し，SEMの利用が容易になりました。EQSやMplus，特にMplusには定評があります。\n一方，オープンソースのソフトウェアとして，Rでは，lavaan，OpenMx，semPLSなどが開発され，研究者にとって費用をかけずにSEMを実践できる環境が拡大しています。\n応用分野も拡大しており，社会科学，行動科学，教育学，心理学，マーケティング，経営管理などから，工学，コンピュータサイエンス，生物学などの自然科学分野にまで広がっています。\nSEMには * 潜在成長曲線 (Latent Growth Curve, LGC) モデル * ベイズSEM (Bayesian SEM, BSEM) * マルチレベル SEM (Multilevel SEM) などの発展がみられ，より複雑な理論モデルを分析できるようになっています。\n\n\n6.0.5 確認的因子分析モデル\n潜在変数モデルの基本形として，確認的因子分析モデル（Confirmatory Factor Analysis; CFA）を実行します。\n\n\nCode\nrequire(tidyverse)\n\n\nLoading required package: tidyverse\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nrequire(lavaan)\n\n\nLoading required package: lavaan\nThis is lavaan 0.6-19\nlavaan is FREE software! Please report any bugs.\n\n\nCode\nflnm &lt;- \"~/Downloads/personality.xlsx\"\ntbl_personality &lt;- readxl::read_xlsx(flnm)\ntbl_personality &lt;- tbl_personality %&gt;%\n  rename(\n    Agr1 = 関係1, Con1 = 意志1, Ext1 = 活動1, Emo1 = 情動1, Int1 = 堅実1,\n    Agr2 = 関係2, Con2 = 意志2, Ext2 = 活動2, Emo2 = 情動2, Int2 = 堅実2,\n    Agr3 = 関係3, Con3 = 意志3, Ext3 = 活動3, Emo3 = 情動3, Int3 = 堅実3,\n    Agr4 = 関係4, Con4 = 意志4, Ext4 = 活動4, Emo4 = 情動4, Int4 = 堅実4,\n    Agr5 = 関係5, Con5 = 意志5, Ext5 = 活動5, Emo5 = 情動5, Int5 = 堅実5\n    )\n  # Agreeableness       関係\n  # Conscientiousness   意志\n  # Extraversion        活動\n  # Emotional Stability 情動\n  # Intellect           堅実\nmdl_personality &lt;- '\n  Agr =~ Agr1 + Agr2 + Agr3 + Agr4 + Agr5\n  Con =~ Con1 + Con2 + Con3 + Con4 + Con5\n  Ext =~ Ext1 + Ext2 + Ext3 + Ext4 + Ext5\n  Emo =~ Emo1 + Emo2 + Emo3 + Emo4 + Emo5\n  Int =~ Int1 + Int2 + Int3 + Int4 + Int5\n'\nrslt_personality &lt;-\n  cfa(model = mdl_personality, data = tbl_personality) # std.lv\nsummary(rslt_personality, standard = TRUE, rsquare = TRUE, ci = TRUE, fit.measure = TRUE)\n\n\nlavaan 0.6-19 ended normally after 56 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        60\n\n  Number of observations                          2236\n\nModel Test User Model:\n                                                      \n  Test statistic                              3843.296\n  Degrees of freedom                               265\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                             16560.077\n  Degrees of freedom                               300\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.780\n  Tucker-Lewis Index (TLI)                       0.751\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -91289.278\n  Loglikelihood unrestricted model (H1)     -89367.630\n                                                      \n  Akaike (AIC)                              182698.556\n  Bayesian (BIC)                            183041.303\n  Sample-size adjusted Bayesian (SABIC)     182850.673\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.078\n  90 Percent confidence interval - lower         0.076\n  90 Percent confidence interval - upper         0.080\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.042\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.076\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n  Agr =~                                                                \n    Agr1              1.000                               1.000    1.000\n    Agr2             -1.595    0.119  -13.378    0.000   -1.829   -1.361\n    Agr3             -2.077    0.151  -13.791    0.000   -2.373   -1.782\n    Agr4             -1.583    0.127  -12.502    0.000   -1.831   -1.334\n    Agr5             -1.852    0.136  -13.579    0.000   -2.119   -1.585\n  Con =~                                                                \n    Con1              1.000                               1.000    1.000\n    Con2              1.162    0.063   18.575    0.000    1.039    1.285\n    Con3              1.085    0.060   18.025    0.000    0.967    1.202\n    Con4             -1.456    0.072  -20.321    0.000   -1.596   -1.315\n    Con5             -1.554    0.080  -19.339    0.000   -1.712   -1.397\n  Ext =~                                                                \n    Ext1              1.000                               1.000    1.000\n    Ext2              1.229    0.054   22.760    0.000    1.123    1.334\n    Ext3             -0.955    0.044  -21.821    0.000   -1.040   -0.869\n    Ext4             -1.132    0.049  -22.933    0.000   -1.229   -1.036\n    Ext5             -0.823    0.041  -19.948    0.000   -0.904   -0.743\n  Emo =~                                                                \n    Emo1              1.000                               1.000    1.000\n    Emo2              0.951    0.025   37.549    0.000    0.902    1.001\n    Emo3              0.897    0.026   34.192    0.000    0.846    0.949\n    Emo4              0.694    0.026   26.358    0.000    0.642    0.746\n    Emo5              0.642    0.028   23.208    0.000    0.588    0.696\n  Int =~                                                                \n    Int1              1.000                               1.000    1.000\n    Int2             -1.058    0.072  -14.654    0.000   -1.200   -0.917\n    Int3              1.368    0.075   18.182    0.000    1.221    1.516\n    Int4              0.413    0.049    8.390    0.000    0.317    0.510\n    Int5             -1.006    0.064  -15.717    0.000   -1.131   -0.880\n   Std.lv  Std.all\n                  \n    0.460    0.330\n   -0.734   -0.634\n   -0.955   -0.741\n   -0.728   -0.503\n   -0.852   -0.678\n                  \n    0.652    0.536\n    0.758    0.578\n    0.707    0.550\n   -0.949   -0.697\n   -1.014   -0.622\n                  \n    0.907    0.560\n    1.114    0.694\n   -0.866   -0.645\n   -1.027   -0.704\n   -0.746   -0.561\n                  \n    1.284    0.821\n    1.222    0.796\n    1.152    0.722\n    0.891    0.571\n    0.825    0.509\n                  \n    0.629    0.562\n   -0.666   -0.431\n    0.861    0.722\n    0.260    0.221\n   -0.633   -0.476\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n  Agr ~~                                                                \n    Con              -0.098    0.011   -8.529    0.000   -0.120   -0.075\n    Ext               0.289    0.025   11.452    0.000    0.239    0.338\n    Emo               0.122    0.018    6.855    0.000    0.087    0.157\n    Int              -0.078    0.011   -7.371    0.000   -0.098   -0.057\n  Con ~~                                                                \n    Ext              -0.213    0.020  -10.607    0.000   -0.252   -0.173\n    Emo              -0.234    0.025   -9.499    0.000   -0.282   -0.186\n    Int               0.117    0.014    8.374    0.000    0.089    0.144\n  Ext ~~                                                                \n    Emo               0.272    0.032    8.424    0.000    0.209    0.335\n    Int              -0.256    0.022  -11.765    0.000   -0.298   -0.213\n  Emo ~~                                                                \n    Int              -0.092    0.023   -4.036    0.000   -0.137   -0.047\n   Std.lv  Std.all\n                  \n   -0.326   -0.326\n    0.693    0.693\n    0.207    0.207\n   -0.268   -0.268\n                  \n   -0.360   -0.360\n   -0.279   -0.279\n    0.284    0.284\n                  \n    0.234    0.234\n   -0.448   -0.448\n                  \n   -0.114   -0.114\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n   .Agr1              1.725    0.053   32.366    0.000    1.621    1.830\n   .Agr2              0.800    0.029   27.408    0.000    0.742    0.857\n   .Agr3              0.749    0.033   22.455    0.000    0.683    0.814\n   .Agr4              1.566    0.051   30.453    0.000    1.465    1.667\n   .Agr5              0.851    0.033   25.743    0.000    0.786    0.916\n   .Con1              1.054    0.036   29.030    0.000    0.983    1.125\n   .Con2              1.144    0.041   27.927    0.000    1.064    1.225\n   .Con3              1.156    0.040   28.702    0.000    1.077    1.235\n   .Con4              0.955    0.041   23.026    0.000    0.874    1.036\n   .Con5              1.627    0.061   26.462    0.000    1.506    1.747\n   .Ext1              1.795    0.060   29.892    0.000    1.678    1.913\n   .Ext2              1.336    0.051   26.168    0.000    1.236    1.436\n   .Ext3              1.052    0.038   27.886    0.000    0.978    1.126\n   .Ext4              1.074    0.042   25.751    0.000    0.992    1.156\n   .Ext5              1.211    0.041   29.874    0.000    1.132    1.291\n   .Emo1              0.797    0.038   20.788    0.000    0.722    0.872\n   .Emo2              0.862    0.038   22.748    0.000    0.787    0.936\n   .Emo3              1.219    0.045   26.884    0.000    1.131    1.308\n   .Emo4              1.640    0.054   30.599    0.000    1.535    1.745\n   .Emo5              1.950    0.062   31.403    0.000    1.828    2.071\n   .Int1              0.858    0.033   26.204    0.000    0.794    0.922\n   .Int2              1.945    0.065   30.040    0.000    1.818    2.072\n   .Int3              0.682    0.040   17.205    0.000    0.604    0.760\n   .Int4              1.313    0.040   32.692    0.000    1.235    1.392\n   .Int5              1.366    0.047   29.009    0.000    1.274    1.458\n    Agr               0.212    0.030    7.164    0.000    0.154    0.269\n    Con               0.425    0.036   11.849    0.000    0.355    0.496\n    Ext               0.822    0.063   13.047    0.000    0.698    0.945\n    Emo               1.649    0.075   21.871    0.000    1.502    1.797\n    Int               0.396    0.034   11.622    0.000    0.329    0.463\n   Std.lv  Std.all\n    1.725    0.891\n    0.800    0.598\n    0.749    0.451\n    1.566    0.747\n    0.851    0.540\n    1.054    0.713\n    1.144    0.666\n    1.156    0.698\n    0.955    0.514\n    1.627    0.613\n    1.795    0.686\n    1.336    0.519\n    1.052    0.584\n    1.074    0.505\n    1.211    0.685\n    0.797    0.326\n    0.862    0.366\n    1.219    0.479\n    1.640    0.674\n    1.950    0.741\n    0.858    0.684\n    1.945    0.814\n    0.682    0.479\n    1.313    0.951\n    1.366    0.773\n    1.000    1.000\n    1.000    1.000\n    1.000    1.000\n    1.000    1.000\n    1.000    1.000\n\nR-Square:\n                   Estimate\n    Agr1              0.109\n    Agr2              0.402\n    Agr3              0.549\n    Agr4              0.253\n    Agr5              0.460\n    Con1              0.287\n    Con2              0.334\n    Con3              0.302\n    Con4              0.486\n    Con5              0.387\n    Ext1              0.314\n    Ext2              0.481\n    Ext3              0.416\n    Ext4              0.495\n    Ext5              0.315\n    Emo1              0.674\n    Emo2              0.634\n    Emo3              0.521\n    Emo4              0.326\n    Emo5              0.259\n    Int1              0.316\n    Int2              0.186\n    Int3              0.521\n    Int4              0.049\n    Int5              0.227\n\n\n適合度の一覧は関数fitMeasures()で得られます。\n\n\nCode\nfitMeasures(rslt_personality)\n\n\n                 npar                  fmin                 chisq \n               60.000                 0.859              3843.296 \n                   df                pvalue        baseline.chisq \n              265.000                 0.000             16560.077 \n          baseline.df       baseline.pvalue                   cfi \n              300.000                 0.000                 0.780 \n                  tli                  nnfi                   rfi \n                0.751                 0.751                 0.737 \n                  nfi                  pnfi                   ifi \n                0.768                 0.678                 0.780 \n                  rni                  logl     unrestricted.logl \n                0.780            -91289.278            -89367.630 \n                  aic                   bic                ntotal \n           182698.556            183041.303              2236.000 \n                 bic2                 rmsea        rmsea.ci.lower \n           182850.673                 0.078                 0.076 \n       rmsea.ci.upper        rmsea.ci.level          rmsea.pvalue \n                0.080                 0.900                 0.000 \n       rmsea.close.h0 rmsea.notclose.pvalue     rmsea.notclose.h0 \n                0.050                 0.042                 0.080 \n                  rmr            rmr_nomean                  srmr \n                0.156                 0.156                 0.076 \n         srmr_bentler   srmr_bentler_nomean                  crmr \n                0.076                 0.076                 0.079 \n          crmr_nomean            srmr_mplus     srmr_mplus_nomean \n                0.079                 0.076                 0.076 \n                cn_05                 cn_01                   gfi \n              177.847               188.033                 0.862 \n                 agfi                  pgfi                   mfi \n                0.830                 0.703                 0.449 \n                 ecvi \n                1.772 \n\n\n以下のようにすれば，特定の適合度指標を表示します。\n\n\nCode\nfitMeasures(rslt_personality, c(\"chisq\", \"df\", \"cfi\", \"rmsea\"))\n\n\n   chisq       df      cfi    rmsea \n3843.296  265.000    0.780    0.078 \n\n\n\n\n6.0.6 共分散構造分析\n情動を他の因子で説明するモデルを分析してみましょう。\n\n\nCode\nmdl_prsn_sem &lt;- '\n  Agr =~ Agr1 + Agr2 + Agr3 + Agr4 + Agr5\n  Con =~ Con1 + Con2 + Con3 + Con4 + Con5\n  Ext =~ Ext1 + Ext2 + Ext3 + Ext4 + Ext5\n  Emo =~ Emo1 + Emo2 + Emo3 + Emo4 + Emo5\n  Int =~ Int1 + Int2 + Int3 + Int4 + Int5\n  Emo ~ Agr + Con + Ext + Int\n'\nrslt_prsn_sem &lt;-\n  cfa(model = mdl_prsn_sem, data = tbl_personality)\nsummary(rslt_prsn_sem, standard = TRUE, rsquare = TRUE, ci = TRUE, fit.measure = TRUE)\n\n\nlavaan 0.6-19 ended normally after 63 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        60\n\n  Number of observations                          2236\n\nModel Test User Model:\n                                                      \n  Test statistic                              3843.296\n  Degrees of freedom                               265\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                             16560.077\n  Degrees of freedom                               300\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.780\n  Tucker-Lewis Index (TLI)                       0.751\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -91289.278\n  Loglikelihood unrestricted model (H1)     -89367.630\n                                                      \n  Akaike (AIC)                              182698.556\n  Bayesian (BIC)                            183041.303\n  Sample-size adjusted Bayesian (SABIC)     182850.673\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.078\n  90 Percent confidence interval - lower         0.076\n  90 Percent confidence interval - upper         0.080\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.042\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.076\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n  Agr =~                                                                \n    Agr1              1.000                               1.000    1.000\n    Agr2             -1.595    0.119  -13.378    0.000   -1.829   -1.361\n    Agr3             -2.077    0.151  -13.791    0.000   -2.373   -1.782\n    Agr4             -1.583    0.127  -12.502    0.000   -1.831   -1.334\n    Agr5             -1.852    0.136  -13.579    0.000   -2.119   -1.585\n  Con =~                                                                \n    Con1              1.000                               1.000    1.000\n    Con2              1.162    0.063   18.575    0.000    1.039    1.285\n    Con3              1.085    0.060   18.025    0.000    0.967    1.202\n    Con4             -1.456    0.072  -20.321    0.000   -1.596   -1.315\n    Con5             -1.554    0.080  -19.339    0.000   -1.712   -1.397\n  Ext =~                                                                \n    Ext1              1.000                               1.000    1.000\n    Ext2              1.229    0.054   22.760    0.000    1.123    1.334\n    Ext3             -0.955    0.044  -21.821    0.000   -1.040   -0.869\n    Ext4             -1.132    0.049  -22.933    0.000   -1.229   -1.036\n    Ext5             -0.823    0.041  -19.949    0.000   -0.904   -0.743\n  Emo =~                                                                \n    Emo1              1.000                               1.000    1.000\n    Emo2              0.951    0.025   37.549    0.000    0.902    1.001\n    Emo3              0.897    0.026   34.192    0.000    0.846    0.949\n    Emo4              0.694    0.026   26.358    0.000    0.642    0.746\n    Emo5              0.642    0.028   23.208    0.000    0.588    0.696\n  Int =~                                                                \n    Int1              1.000                               1.000    1.000\n    Int2             -1.058    0.072  -14.655    0.000   -1.200   -0.917\n    Int3              1.368    0.075   18.182    0.000    1.221    1.515\n    Int4              0.413    0.049    8.390    0.000    0.317    0.510\n    Int5             -1.006    0.064  -15.717    0.000   -1.131   -0.880\n   Std.lv  Std.all\n                  \n    0.460    0.330\n   -0.734   -0.634\n   -0.955   -0.741\n   -0.728   -0.503\n   -0.852   -0.678\n                  \n    0.652    0.536\n    0.758    0.578\n    0.707    0.550\n   -0.949   -0.697\n   -1.014   -0.622\n                  \n    0.907    0.560\n    1.114    0.694\n   -0.866   -0.645\n   -1.027   -0.704\n   -0.746   -0.561\n                  \n    1.284    0.821\n    1.222    0.796\n    1.152    0.722\n    0.891    0.571\n    0.825    0.509\n                  \n    0.629    0.562\n   -0.666   -0.431\n    0.861    0.722\n    0.260    0.221\n   -0.633   -0.476\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n  Emo ~                                                                 \n    Agr               0.144    0.119    1.209    0.227   -0.090    0.379\n    Con              -0.438    0.060   -7.306    0.000   -0.556   -0.321\n    Ext               0.179    0.067    2.679    0.007    0.048    0.311\n    Int               0.040    0.067    0.598    0.550   -0.091    0.171\n   Std.lv  Std.all\n                  \n    0.052    0.052\n   -0.222   -0.222\n    0.127    0.127\n    0.020    0.020\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n  Agr ~~                                                                \n    Con              -0.098    0.011   -8.529    0.000   -0.120   -0.075\n    Ext               0.289    0.025   11.452    0.000    0.239    0.338\n    Int              -0.078    0.011   -7.371    0.000   -0.098   -0.057\n  Con ~~                                                                \n    Ext              -0.213    0.020  -10.607    0.000   -0.252   -0.173\n    Int               0.117    0.014    8.374    0.000    0.089    0.144\n  Ext ~~                                                                \n    Int              -0.256    0.022  -11.765    0.000   -0.298   -0.213\n   Std.lv  Std.all\n                  \n   -0.326   -0.326\n    0.693    0.693\n   -0.268   -0.268\n                  \n   -0.360   -0.360\n    0.284    0.284\n                  \n   -0.448   -0.448\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n   .Agr1              1.725    0.053   32.366    0.000    1.621    1.830\n   .Agr2              0.800    0.029   27.409    0.000    0.743    0.857\n   .Agr3              0.749    0.033   22.455    0.000    0.683    0.814\n   .Agr4              1.566    0.051   30.453    0.000    1.465    1.667\n   .Agr5              0.851    0.033   25.742    0.000    0.786    0.916\n   .Con1              1.054    0.036   29.030    0.000    0.983    1.125\n   .Con2              1.144    0.041   27.927    0.000    1.064    1.225\n   .Con3              1.156    0.040   28.702    0.000    1.077    1.235\n   .Con4              0.955    0.041   23.026    0.000    0.874    1.036\n   .Con5              1.627    0.061   26.462    0.000    1.506    1.747\n   .Ext1              1.795    0.060   29.892    0.000    1.678    1.913\n   .Ext2              1.336    0.051   26.168    0.000    1.236    1.436\n   .Ext3              1.052    0.038   27.886    0.000    0.978    1.126\n   .Ext4              1.074    0.042   25.751    0.000    0.992    1.156\n   .Ext5              1.211    0.041   29.874    0.000    1.132    1.291\n   .Emo1              0.797    0.038   20.788    0.000    0.722    0.872\n   .Emo2              0.862    0.038   22.748    0.000    0.787    0.936\n   .Emo3              1.219    0.045   26.884    0.000    1.131    1.308\n   .Emo4              1.640    0.054   30.599    0.000    1.535    1.745\n   .Emo5              1.949    0.062   31.403    0.000    1.828    2.071\n   .Int1              0.858    0.033   26.203    0.000    0.794    0.922\n   .Int2              1.945    0.065   30.040    0.000    1.818    2.072\n   .Int3              0.682    0.040   17.206    0.000    0.604    0.760\n   .Int4              1.313    0.040   32.692    0.000    1.235    1.392\n   .Int5              1.366    0.047   29.009    0.000    1.274    1.458\n    Agr               0.212    0.030    7.164    0.000    0.154    0.269\n    Con               0.425    0.036   11.849    0.000    0.355    0.496\n    Ext               0.822    0.063   13.047    0.000    0.698    0.945\n   .Emo               1.484    0.069   21.358    0.000    1.348    1.620\n    Int               0.396    0.034   11.623    0.000    0.329    0.463\n   Std.lv  Std.all\n    1.725    0.891\n    0.800    0.598\n    0.749    0.451\n    1.566    0.747\n    0.851    0.540\n    1.054    0.713\n    1.144    0.666\n    1.156    0.698\n    0.955    0.514\n    1.627    0.613\n    1.795    0.686\n    1.336    0.519\n    1.052    0.584\n    1.074    0.505\n    1.211    0.685\n    0.797    0.326\n    0.862    0.366\n    1.219    0.479\n    1.640    0.674\n    1.949    0.741\n    0.858    0.684\n    1.945    0.814\n    0.682    0.479\n    1.313    0.951\n    1.366    0.773\n    1.000    1.000\n    1.000    1.000\n    1.000    1.000\n    0.900    0.900\n    1.000    1.000\n\nR-Square:\n                   Estimate\n    Agr1              0.109\n    Agr2              0.402\n    Agr3              0.549\n    Agr4              0.253\n    Agr5              0.460\n    Con1              0.287\n    Con2              0.334\n    Con3              0.302\n    Con4              0.486\n    Con5              0.387\n    Ext1              0.314\n    Ext2              0.481\n    Ext3              0.416\n    Ext4              0.495\n    Ext5              0.315\n    Emo1              0.674\n    Emo2              0.634\n    Emo3              0.521\n    Emo4              0.326\n    Emo5              0.259\n    Int1              0.316\n    Int2              0.186\n    Int3              0.521\n    Int4              0.049\n    Int5              0.227\n    Emo               0.100\n\n\nパス図を出力するパッケージsemPlotを利用します。\n\n\nCode\nrequire(semPlot)\n\n\nLoading required package: semPlot\n\n\nCode\nsemPaths(rslt_prsn_sem, # 以下はおすすめ設定\n  what = \"std\", style = \"lisrel\",\n  #edge.label.cex = 2,\n  edge.color = \"black\", fade = FALSE,\n  nCharNodes = 0\n  #,sizeMan = 10, esize = 3 # 適宜変更\n)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>潜在変数モデル</span>"
    ]
  }
]